import { QUESTION_PROMPT } from "@/services/Constants";
import { NextResponse } from "next/server";
import OpenAI from "openai";

export async function POST(req) {
  const { jobPosition, jobDescription, duration, type } = await req.json();

  const FINAL_PROMPT = QUESTION_PROMPT
    .replace('{{jobTitle}}', jobPosition)
    .replace('{{jobDescription}}', jobDescription)
    .replace('{{duration}}', duration)
    .replace('{{type}}', type);

  console.log({ jobPosition, jobDescription, duration, type });

  try {
    const openai = new OpenAI({
      baseURL: "https://openrouter.ai/api/v1",
      apiKey: process.env.OPENROUTER_API_KEY,
    });

    const completion = await openai.chat.completions.create({
      model: "openai/gpt-3.5-turbo",
      messages: [
        { role: "user", content: FINAL_PROMPT }
      ],
    });

    console.log("Full OpenAI response:", completion);

    if (completion?.choices && completion.choices.length > 0) {
      console.log(completion.choices[0].message);
      return NextResponse.json(completion.choices[0].message);
    } else {
      console.error("No choices returned by OpenAI:", completion);
      return NextResponse.json({ error: "No response generated by AI model." }, { status: 500 });
    }
  } catch (e) {
    console.error("OpenAI Error:", e);
    return NextResponse.json({ error: "AI request failed", details: e.message || e }, { status: 500 });
  }
}
